{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0077ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision.models import mobilenet_v2\n",
    "from torchvision.models.feature_extraction import create_feature_extractor\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cab59022",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'MobileNetV2(\\n  (features): Sequential(\\n    (0): Conv2dNormActivation(\\n      (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\\n      (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      (2): ReLU6(inplace=True)\\n    )\\n    (1): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\\n          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2d(32, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (2): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(16, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(96, 96, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=96, bias=False)\\n          (1): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(96, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (3): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=144, bias=False)\\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(144, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (4): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(24, 144, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(144, 144, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=144, bias=False)\\n          (1): BatchNorm2d(144, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(144, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (5): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (6): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=192, bias=False)\\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(192, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (7): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(32, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(192, 192, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=192, bias=False)\\n          (1): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(192, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (8): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (9): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (10): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(384, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (11): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(64, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=384, bias=False)\\n          (1): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(384, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (12): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (13): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=576, bias=False)\\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(576, 96, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (14): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(96, 576, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(576, 576, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=576, bias=False)\\n          (1): BatchNorm2d(576, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(576, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (15): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (16): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(160, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (17): InvertedResidual(\\n      (conv): Sequential(\\n        (0): Conv2dNormActivation(\\n          (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (1): Conv2dNormActivation(\\n          (0): Conv2d(960, 960, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=960, bias=False)\\n          (1): BatchNorm2d(960, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n          (2): ReLU6(inplace=True)\\n        )\\n        (2): Conv2d(960, 320, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n        (3): BatchNorm2d(320, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      )\\n    )\\n    (18): Conv2dNormActivation(\\n      (0): Conv2d(320, 1280, kernel_size=(1, 1), stride=(1, 1), bias=False)\\n      (1): BatchNorm2d(1280, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\\n      (2): ReLU6(inplace=True)\\n    )\\n  )\\n  (classifier): Sequential(\\n    (0): Dropout(p=0.2, inplace=False)\\n    (1): Linear(in_features=1280, out_features=1000, bias=True)\\n  )\\n)'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = mobilenet_v2(weights = 'MobileNet_V2_Weights.DEFAULT')\n",
    "#model.eval()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c477a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Transforms\n",
    "from matplotlib import transforms\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    # Input is 96x96. We RandomCrop to 64x64\n",
    "    transforms.RandomCrop(64),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=15),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    # CenterCrop to 64x64 for testing\n",
    "    transforms.CenterCrop(64),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                         std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load Datasets\n",
    "# Note: We load the training data twice to apply different transforms to train vs val subsets seamlessly\n",
    "# or we can rely on Subset. However, Subset inherits the dataset's transform.\n",
    "# A cleaner way is to create two dataset instances.\n",
    "\n",
    "full_train_dataset = datasets.STL10(root='./data', split='train', download=True, transform=None)\n",
    "test_dataset = datasets.STL10(root='./data', split='test', download=True, transform=test_transform)\n",
    "\n",
    "# Split indices\n",
    "targets = full_train_dataset.labels\n",
    "train_idx, val_idx = train_test_split(\n",
    "    np.arange(len(full_train_dataset)),\n",
    "    test_size=0.2,\n",
    "    shuffle=True,\n",
    "    stratify=targets,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Create Subsets\n",
    "# To properly handle transforms, we'll create two base datasets with correct transforms\n",
    "train_base = datasets.STL10(root='./data', split='train', download=True, transform=train_transform)\n",
    "val_base = datasets.STL10(root='./data', split='train', download=True, transform=test_transform)\n",
    "\n",
    "# Full training datasets for final training\n",
    "train_ds_aug = train_base\n",
    "train_ds_clean = val_base\n",
    "\n",
    "train_set = Subset(train_base, train_idx)\n",
    "val_set = Subset(val_base, val_idx)\n",
    "\n",
    "# Create DataLoader for test evaluation\n",
    "batch_size = 128 # Increased batch size for more stable gradients\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(f\"Train Size: {len(train_set)} | Val Size: {len(val_set)} | Test Size: {len(test_dataset)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deep_learning_hw",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
